{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd450858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "# Load text (update path as needed)\n",
    "with open(\"/content/drive/MyDrive/DL_dataset/LSTM_network.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()  # lowercase for uniformity\n",
    "\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenize text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(\"Total words:\", total_words)\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e484b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_sequences = []\n",
    "sentences = re.split(r'\\.\\s*', text.strip())\n",
    "\n",
    "for line in sentences:\n",
    "    line = line.strip()\n",
    "    if not line:\n",
    "        continue\n",
    "    tokens = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(tokens)):\n",
    "        n_gram_sequence = tokens[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "print(input_sequences[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbb43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_seq_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre')\n",
    "\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=total_words, output_dim=128, input_length=max_seq_len - 1),\n",
    "    LSTM(128, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(32),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(X, y, epochs=500, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d50891",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_next_word(model, tokenizer, text_seed, max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text_seed])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_index = np.argmax(predicted, axis=1)[0]\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_index:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "seed_text = \"deep learning\"\n",
    "next_word = predict_next_word(model, tokenizer, seed_text, max_seq_len)\n",
    "print(f\"Input: {seed_text}\")\n",
    "print(f\"Predicted next word: {next_word}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
